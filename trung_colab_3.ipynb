{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trung_colab.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trungphan9x/ML_project1/blob/master/trung_colab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsGZP9Mq8rbd"
      },
      "source": [
        "# CS582 Machine Learning - Mini Project 1\n",
        "\n",
        "Professor: Anthony Sander\n",
        "\n",
        "Team:\n",
        "\n",
        "\n",
        "*   Khoa Nam Nguyen\n",
        "*   Thai Trung Phan\n",
        "\n",
        "Dataset: https://www.kaggle.com/camnugent/california-housing-prices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfjurcPy7sHf"
      },
      "source": [
        "# Loading all libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rNqDtoM67F2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e8dae3-d5a2-4d37-90b5-29a002bbff64"
      },
      "source": [
        "!pip uninstall scikit-learn\n",
        "!pip install scikit-learn==0.24.0\n",
        "!pip install auto-sklearn\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "\n",
        "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
        "import autosklearn.classification\n",
        "import sklearn.model_selection\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 uninstall [options] <package> ...\n",
            "  pip3 uninstall [options] -r <requirements file> ...\n",
            "\n",
            "no such option: -f\n",
            "Requirement already satisfied: scikit-learn==0.24.0 in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (1.4.1)\n",
            "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.7/dist-packages (0.12.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2.5.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.1.5)\n",
            "Requirement already satisfied: scipy<1.7,>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.4.1)\n",
            "Requirement already satisfied: distributed>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2021.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.4.19)\n",
            "Requirement already satisfied: pyrfr<0.9,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.8.2)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.24.0)\n",
            "Requirement already satisfied: pynisher>=0.6.3 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.6.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (1.19.5)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (2021.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (57.2.0)\n",
            "Requirement already satisfied: smac<0.14,>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn) (0.13.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (0.29.23)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn) (2.4.7)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (2.0.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (5.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (1.6.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (0.11.1)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask->auto-sklearn) (21.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask->auto-sklearn) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask->auto-sklearn) (2021.7.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask->auto-sklearn) (0.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.24.0->auto-sklearn) (2.2.0)\n",
            "Requirement already satisfied: lazy-import in /usr/local/lib/python3.7/dist-packages (from smac<0.14,>=0.13.1->auto-sklearn) (0.2.2)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.2.0->auto-sklearn) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd5tnNAfgx2x"
      },
      "source": [
        "!pip install lime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChTnA0RvjFEE"
      },
      "source": [
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOscPxlc9vaR"
      },
      "source": [
        "# STEP 1: LOADING DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjCH7JJOeS0k"
      },
      "source": [
        "Min of 500 samples , must include at least one categorical feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdYdcPyz6u6X"
      },
      "source": [
        "!git clone https://github.com/trungphan9x/ML_project1.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUFFiAhE69ml"
      },
      "source": [
        "housing = pd.read_csv('/content/ML_project1/dataset/Cali_housing_prices/housing.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hisRBUK_WfNZ"
      },
      "source": [
        "# STEP 2: EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgCb7o4YeH6Z"
      },
      "source": [
        "# Identify if there are any missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NZnCISpXUU9"
      },
      "source": [
        "\n",
        "> There are 20,640 instances in the dataset. Notice that the total_bed rooms attribute has only 20,433 nonnull values, meaning that 207 districts are missing this feature. We will need to take care of this.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VI0T2AR6_tq"
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C5NUrDjes1g"
      },
      "source": [
        "# Identify categorical feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyt6rJcga_II"
      },
      "source": [
        "\n",
        "\n",
        "> All attributes are numerical, except the ocean_proximity field. When you looked at the top five rows, you probably noticed that the values in the ocean_proximity column were repetitive, which means that it is probably a categorical attribute "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYD1JDnOYbM8"
      },
      "source": [
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIobhlV7cBx8"
      },
      "source": [
        "\n",
        "\n",
        "> Check what categories exist and how many districts belong to each category\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZZUcFDGcIYP"
      },
      "source": [
        "housing['ocean_proximity'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6znj_qdue5xJ"
      },
      "source": [
        "# Summary of the numerical atributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLDLMOLDc1rs"
      },
      "source": [
        "housing.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA7hb9V-e-5v"
      },
      "source": [
        "# Ploting a histogram of each numerical atribute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbo7ibxVdLN1"
      },
      "source": [
        "housing.hist(bins=50, figsize=(20,15)) \n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsMT3sAbddoa"
      },
      "source": [
        "\n",
        "> There are a few things you might notice in these histograms:\n",
        "\n",
        "\n",
        "1.   The median house value is our target attribute (our labels).\n",
        "2.   The median income attribute: the numbers represent roughly tens of thousands of dollars (e.g., 3 actually means about $30,000).\n",
        "3.   These attributes have very different scales.\n",
        "4.   Finally, many histograms are tail-heavy: they extend much farther to the right of the median than to the left. This may make it a bit harder for some Machine Learning algorithms to detect patterns. We will try transforming these attributes later on to have more bell-shaped distributions.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lstlm84qoh6w"
      },
      "source": [
        "# Visualizing Geographical Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbMDPn5_o4_x"
      },
      "source": [
        "Create a scatterplot of all districts to visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GVMH9pZo7Uc"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-_GKr5CpDm1"
      },
      "source": [
        "This looks like California actually. Setting the alpha option to 0.1 makes it much easier to visualize the places where there is a high density of data points:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM2fXgbhpKtX"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPxXMxOBphz9"
      },
      "source": [
        "Now that’s much better: you can clearly see the high-density areas, namely the Bay Area and around Los Angeles and San Diego, plus a long line of fairly high density in the Central Valley, in particular around Sacramento and Fresno.\n",
        "\n",
        "\n",
        "Now let’s look at the housing prices (Figure 2-13). The radius of each circle represents the district’s population (option s), and the color represents the price (option c). We will use a predefined color map (option cmap) called jet, which ranges from blue (low values) to red (high prices):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PODKBOIpqJV"
      },
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "             s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "             c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        "             sharex=False)\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfQshYfxqZMG"
      },
      "source": [
        "This image tells you that the housing prices are very much related to the location (e.g., close to the ocean) and to the population density. A clustering algorithm should be useful for detecting the main cluster and for adding new features that measure the proximity to the cluster centers. The ocean proximity attribute may be useful as well, although in Northern California the housing prices in coastal districts are not too high, so it is not a simple rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qpOmlbuqmFP"
      },
      "source": [
        "# Correlations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J57APKiq_tU"
      },
      "source": [
        "corr_matrix = housing.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G71C-t5rEby"
      },
      "source": [
        "Now let’s look at how much each attribute correlates with the median house value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcctVTaSrHDq"
      },
      "source": [
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0_UHOLqrWz7"
      },
      "source": [
        "When it is close to 1, it means that there is a strong positive correlation; for example, the median house value tends to go up when the median income goes up\n",
        "\n",
        "When the coefficient is close to –1, it means that there is a strong negative correlation; you can see a small negative correlation between the latitude and the median house value (i.e., prices have a slight tendency to go down when you go north)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zatdu6IUr1oZ"
      },
      "source": [
        "Another way to check for correlation between attributes is to use the pandas scatter_matrix() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ8Nu9zHrqR8"
      },
      "source": [
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHmw9NlqsITQ"
      },
      "source": [
        " housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOzel650sTyA"
      },
      "source": [
        "# Atribute Combination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y7tTZzbsYAo"
      },
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWstL_8msn8c"
      },
      "source": [
        "corr_matrix = housing.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlN28chlstD0"
      },
      "source": [
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XROFyk_3s4ey"
      },
      "source": [
        "The new bedrooms_per_room attribute is much more correlated with the median house value than the total number of rooms or bedrooms.\n",
        "\n",
        "Apparently houses with a lower bedroom/room ratio tend to be more expensive. \n",
        "\n",
        "The larger the houses, the more expensive they are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_MWiyD-hnz7"
      },
      "source": [
        "# STEP 3: DATA PREPARATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4idg6m5F_Psw"
      },
      "source": [
        "# Handle the categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YDRU0x-_QV0"
      },
      "source": [
        "#le = LabelEncoder()\n",
        "#housing['ocean_proximity'] = le.fit_transform(housing['ocean_proximity'])\n",
        "housing = pd.get_dummies(housing, columns=['ocean_proximity'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by4JQU5mfKKC"
      },
      "source": [
        "housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbvSxJaIybFc"
      },
      "source": [
        "#  Processing missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7PbP_fQzVmY"
      },
      "source": [
        "Create a SimpleImputer instance, specifying that you want to replace each attribute’s missing values with the median of that attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV8AyFDxzYvv"
      },
      "source": [
        "imputer = SimpleImputer(strategy=\"median\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeiPRPPVzs2n"
      },
      "source": [
        "Fit the imputer instance to the training data using the fit() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQqiBPygzvM5"
      },
      "source": [
        "imputer.fit(housing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UFyARGR0Myw"
      },
      "source": [
        "imputer.statistics_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eq98v310uty"
      },
      "source": [
        "Use this “trained” imputer to transform the training set by replacing missing values with the learned medians:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb7Aj0hK0yOS"
      },
      "source": [
        "X = imputer.transform(housing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCG8uCkD04ej"
      },
      "source": [
        "The result is a plain NumPy array containing the transformed features. If you want to put it back into a pandas DataFrame, it’s simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxkKOb5X07Ws"
      },
      "source": [
        "housing = pd.DataFrame(X, columns=housing.columns, index=housing.index)\n",
        "housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMMbjTyu1DNh"
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWc51TgckOcN"
      },
      "source": [
        "# Convert Regression dataset to Binary Classification dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxX5QTi5N4aS"
      },
      "source": [
        "housing['median_house_value'] = np.where(housing['median_house_value']>200000.0,1,0)\n",
        "housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoJULEb1OmyO"
      },
      "source": [
        "housing['median_house_value'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFHd6ub5lQjc"
      },
      "source": [
        "# Create trainset and testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anre_VeQmjpg"
      },
      "source": [
        "The median income is a very important attribute to predict median housing prices. We may want to ensure that the test set is representative of the various categories of incomes in the whole dataset. So we are gonna create an income category attribute with five categories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY-0DqMllh9r"
      },
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],bins=[0., 1.5, 3.0, 4.5, 6., np.inf],labels=[1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qhcMkkZncNU"
      },
      "source": [
        " housing[\"income_cat\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vazoI-tJnrhe"
      },
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFXeyXHvn1Nh"
      },
      "source": [
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "        strat_train_set = housing.loc[train_index]\n",
        "        strat_test_set = housing.loc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3JKuG5ZoFt6"
      },
      "source": [
        "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKsFCqz5oG4F"
      },
      "source": [
        "strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwvG9kbuoUMg"
      },
      "source": [
        "Then remove the income_cat attribute so the data is back to its original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnhBZzsDxQC9"
      },
      "source": [
        "for set_ in (strat_train_set, strat_test_set): \n",
        "  set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXBo619TxIwr"
      },
      "source": [
        "Separate the predictors and the labels, since we don’t necessarily want to apply the same transformations to the predictors and the target values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ILZBrxgoWWL"
      },
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRMtXNuiptNs"
      },
      "source": [
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT8a1IXIWVgy"
      },
      "source": [
        "housing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Qqt7XcYVBf"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6C3zCpz-gxo"
      },
      "source": [
        "# Nomalization Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l6I2xbo-0yB"
      },
      "source": [
        "# normalize data\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "housing_prepared = std_scaler.fit_transform(housing)\n",
        "X_test_prepared = std_scaler.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2i6X0pt_FTU"
      },
      "source": [
        "housing_prepared = pd.DataFrame(housing_prepared, columns=housing.columns, index=housing.index)\n",
        "housing_prepared"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8SRGFVSZQIe"
      },
      "source": [
        "X_test_prepared = pd.DataFrame(X_test_prepared, columns=X_test.columns, index=X_test.index)\n",
        "X_test_prepared"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FU-Dp08WVF_"
      },
      "source": [
        "# STEP 4: MODEL TUNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00_4o7ABBuvr"
      },
      "source": [
        "Using GridSearchCV to find a great combination of hyperparameter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8mm6kBo_JNg"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "def best_estimator(estimator,param_grid,X,y,cv):\n",
        "  grid = GridSearchCV(estimator, param_grid, cv = cv, scoring = 'accuracy', n_jobs=-1)\n",
        "  grid.fit(X,y)\n",
        "  best_estimator = grid.best_estimator_\n",
        "  best_score = grid.best_score_\n",
        "  print(\"Best Params:\", grid.best_params_)\n",
        "  print(\"Best Score:\", grid.best_score_)\n",
        "  print(\"Best Estimator:\", grid.best_estimator_)\n",
        "  return best_estimator, best_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAyyIFvwHFqi"
      },
      "source": [
        "Plot learning curve: `https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-sfosTrEtNv"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, axe=None, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \n",
        "    if axe is None:\n",
        "        _, axe = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "    plt.title(\"Learning Curve with \"+ title)\n",
        "    axe.set_xlabel(\"Training examples\")\n",
        "    axe.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes,\n",
        "                       return_times=True)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axe.grid()\n",
        "    axe.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axe.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axe.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axe.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axe.legend(loc=\"best\")\n",
        "\n",
        "    return plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6l1sP3_Ak_v"
      },
      "source": [
        "Plot validation curve: `https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCQeL6UaUkSY"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "def plot_validation_curve(estimator, title, X, y, param_name=None, param_range=None, cv= None, n_jobs=None):\n",
        "  train_scores, test_scores = validation_curve(\n",
        "      estimator, X, y, param_name=param_name, param_range=param_range,\n",
        "      scoring=\"accuracy\", n_jobs=1)\n",
        "  train_scores_mean = np.mean(train_scores, axis=1)\n",
        "  train_scores_std = np.std(train_scores, axis=1)\n",
        "  test_scores_mean = np.mean(test_scores, axis=1)\n",
        "  test_scores_std = np.std(test_scores, axis=1)\n",
        "  plt.subplots(figsize=(20, 5))\n",
        "  plt.title(\"Validation Curve with \"+ title)\n",
        "  plt.xlabel(param_name)\n",
        "  plt.ylabel(\"Score\")\n",
        "  plt.ylim(0.0, 1.1)\n",
        "  lw = 2\n",
        "  plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
        "              color=\"darkorange\", lw=lw)\n",
        "  plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                  train_scores_mean + train_scores_std, alpha=0.2,\n",
        "                  color=\"darkorange\", lw=lw)\n",
        "  plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
        "              color=\"navy\", lw=lw)\n",
        "  plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
        "                  test_scores_mean + test_scores_std, alpha=0.2,\n",
        "                  color=\"navy\", lw=lw)\n",
        "  plt.legend(loc=\"best\")\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a1fy3WKu5DR"
      },
      "source": [
        "# 1) SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mE0qFvRw9XF"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "param_svc = {\n",
        "    'C': [0.001, 0.1, 1, 10, 100] #regularization factor\n",
        "}\n",
        "svc_estimator, svc_score = best_estimator(SVC(), param_svc, housing_prepared, housing_labels, 5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0xq1A7xFJwh"
      },
      "source": [
        "plot_learning_curve(svc_estimator, \"SVC\", housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA5EGZvnW_Q5"
      },
      "source": [
        "plot_validation_curve(svc_estimator, \"SVC\", housing_prepared, housing_labels, param_name=\"C\", param_range=[0.001, 0.1, 1, 10, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjc_fJp7OyuH"
      },
      "source": [
        "# 2) KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzThy7DGO1dO"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k_range = np.arange(1,30)\n",
        "param_knn = dict(n_neighbors = k_range)\n",
        "knn_estimator, knn_score = best_estimator(KNeighborsClassifier(), param_knn, housing_prepared, housing_labels, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTrmsUHrPcuL"
      },
      "source": [
        "plot_learning_curve(knn_estimator, \"KNN\", housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcm08XCvQKyp"
      },
      "source": [
        "param_range = [1,3,7,14,20]\n",
        "plot_validation_curve(knn_estimator, \"KNN\", housing_prepared, housing_labels, param_name=\"n_neighbors\", param_range = param_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5IQCI5NR9ki"
      },
      "source": [
        "# 3) Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QchxkR-JSUYf"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_params = {\n",
        "    'C': np.logspace(-3,3,7),\n",
        "    'penalty':['l1','l2']# l1 lasso l2 ridge\n",
        "}\n",
        "log_estimator,log_score = best_estimator(LogisticRegression(max_iter=1000), log_params,housing_prepared, housing_labels,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv0XeNKoTXlN"
      },
      "source": [
        "plot_learning_curve(log_estimator, \"Logistic Regression\", housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeyKCcn_UIPn"
      },
      "source": [
        "param_range = np.logspace(-3,3,7)\n",
        "plot_validation_curve(log_estimator, \"Logistic Regression\", housing_prepared, housing_labels, param_name=\"C\", param_range = param_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utFT20QVWS4Q"
      },
      "source": [
        "# 4) Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWrL04d2WVVs"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree_params = {\n",
        "     'max_depth':np.arange(1,20)\n",
        "}\n",
        "dt_estimator,dt_score = best_estimator(DecisionTreeClassifier(), dtree_params, housing_prepared, housing_labels, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdwbfyaVWkDA"
      },
      "source": [
        "plot_learning_curve(dt_estimator, \"Decision Tree\", housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IuU5MxEWunS"
      },
      "source": [
        "param_range = [1,3,8,12,20]\n",
        "plot_validation_curve(dt_estimator, \"Decision Tree\", housing_prepared, housing_labels, param_name=\"max_depth\", param_range = param_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHbv9je6XCxA"
      },
      "source": [
        "# 5) MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XVDj_94fBIY"
      },
      "source": [
        "`https://scikit-learn.org/stable/modules/neural_networks_supervised.html`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lis9KtICX5bc"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp_params = {\n",
        "    'hidden_layer_sizes': [(5,),(10,),(20,)]\n",
        "}\n",
        "mlp_estimator, mlp_score = best_estimator(MLPClassifier(max_iter=1000), mlp_params, housing_prepared, housing_labels, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aBvbtCBYLsH"
      },
      "source": [
        "plot_learning_curve(mlp_estimator, \"MLP\", housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_duEN99jYRGi"
      },
      "source": [
        "param_range = [1, 20, 50,100]\n",
        "plot_validation_curve(mlp_estimator, \"MLP\", housing_prepared, housing_labels, param_name=\"hidden_layer_sizes\", param_range = param_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRkXJNwFbm_T"
      },
      "source": [
        "# 6) Ensemble - Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ALDllY3broZ"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rForest = [\n",
        "        {'n_estimators': [3, 10, 30, 50, 80, 100, 500], 'max_features': [2, 4, 6, 8, 10, 12]},\n",
        "        {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "]\n",
        "rf_estimator, rf_score = best_estimator(RandomForestClassifier(), rForest, housing_prepared, housing_labels, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN8jJxCudOlL"
      },
      "source": [
        "plot_learning_curve(rf_estimator, \"Random Forest Classifier\", housing_prepared, housing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUAdUCoxdW22"
      },
      "source": [
        "param_range = [3, 10, 30, 50, 80, 100, 500]\n",
        "plot_validation_curve(rf_estimator, \"Random Forest Classifier\", housing_prepared, housing_labels, param_name=\"n_estimators\", param_range = param_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLwSODwTnB-2"
      },
      "source": [
        "# 7) Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x68IF4jnHT4"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "eclf = VotingClassifier(voting='hard', \n",
        "                        estimators=[('svc', svc_estimator), ('knn', knn_estimator), ('log', log_estimator), ('dt', dt_estimator), ('mlp', mlp_estimator), ('rf', rf_estimator)] )\n",
        "eclf = eclf.fit(housing_prepared, housing_labels)\n",
        "y_pred_voting = eclf.predict(X_test_prepared)\n",
        "voting_score = accuracy_score(y_test, y_pred_voting)\n",
        "print(f\"Voting Accuracy Score = {voting_score}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLkDcRRXq9gi"
      },
      "source": [
        "# 8) AutoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ15wBvtrBVK"
      },
      "source": [
        "#Auto-sklearn 2.0 includes latest research on automatically configuring the AutoML system itself and contains a multitude of improvements which speed up the fitting the AutoML system.\n",
        "# from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
        "# import autosklearn.classification\n",
        "# import sklearn.model_selection\n",
        "# import sklearn.datasets\n",
        "# import sklearn.metrics\n",
        "\n",
        "autoMl = autosklearn.classification.AutoSklearnClassifier()\n",
        "autoMl.fit(housing_prepared, housing_labels)\n",
        "\n",
        "y_pred_automl = autoMl.predict(X_test_prepared)\n",
        "autoMl_score =  sklearn.metrics.accuracy_score(y_test, y_pred_automl)\n",
        "print(f\"AutoML Accuracy Score = {autoMl_score}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtMg4iK0DFd7"
      },
      "source": [
        "# AUC Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5uDaiWGDyO7"
      },
      "source": [
        "`https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBkTfutiDJAK"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import metrics\n",
        "def plot_roc_curve(estimators, titles, X, y, ax=None):\n",
        "    if ax is None: _, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "    for i, estimator in enumerate(estimators):\n",
        "      y_pred = estimator.predict(X)\n",
        "      fpr, tpr, _ = roc_curve(y, y_pred)\n",
        "      ax.plot(fpr, tpr, label=f\"{titles[i]}, AUC=\" + \"{:.2f}\".format(metrics.auc(fpr, tpr)))\n",
        "\n",
        "    ax.set_title('AUC curve')\n",
        "    ax.legend(loc='best')\n",
        "    ax.set_xlabel('False positive rate')\n",
        "    ax.set_ylabel('True positive rate') \n",
        "    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    return plt\n",
        "\n",
        "estimators = [svc_estimator, knn_estimator, log_estimator, dt_estimator, mlp_estimator, rf_estimator]\n",
        "titles = ['SVC','KNN','LOG','DT','MLP', 'RF']\n",
        "plot_roc_curve(estimators, titles, X_test_prepared, y_test)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rau-SSsdcVeI"
      },
      "source": [
        "# SHAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oe6lp1eo4DH"
      },
      "source": [
        "`https://www.explorium.ai/blog/interpretability-and-explainability-part-2/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKPqW4h0mnpz"
      },
      "source": [
        "import shap\n",
        "\n",
        "row = 4\n",
        "data_for_prediction = X_test_prepared.iloc[row]  # use 1 arbitrary row of data\n",
        "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
        "\n",
        "explainer = shap.TreeExplainer(dt_estimator)\n",
        "shap_values = explainer.shap_values(data_for_prediction)\n",
        "# The shap_values is a list with two arrays. It’s cumbersome to review raw arrays, but the shap package has a nice way to visualize the results.\n",
        "\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgBrHDLTLb0V"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}